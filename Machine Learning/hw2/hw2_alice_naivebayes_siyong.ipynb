{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3', 'contents', 'chapter', 'i', 'down', 'the', 'rabbit', 'chapter', 'ii', 'the', 'pool', 'of', 'tears', 'chapter']\n",
      "corpus len:  25320\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "f = open('alice_in_wonderland.txt','r')\n",
    "while(1):\n",
    "    line =  f.readline()\n",
    "    if len(line) == 0: break\n",
    "    corpus.extend(line.split())\n",
    "        \n",
    "f.close()\n",
    "corpus = ' '.join(corpus)\n",
    "\n",
    "def clean_word(word):\n",
    "    word = word.lower()\n",
    "    for punctuation in ['\"',\"'\",'.',',','-','?','!',';',':','â€”','(',')','[',']']:\n",
    "        word = word.split(punctuation)[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "\n",
    "corpus = [clean_word(word) for word in corpus.split()]\n",
    "corpus = [word for word in corpus if len(word) > 0]\n",
    "print(corpus[:25])\n",
    "D = len(corpus)\n",
    "print('corpus len: ',D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size (number of distinct words):  2637\n"
     ]
    }
   ],
   "source": [
    "tokenize = {}\n",
    "dictionary = []\n",
    "token = 0\n",
    "for word in corpus:\n",
    "    if word not in tokenize.keys():\n",
    "        tokenize[word] = token\n",
    "        dictionary.append(word)\n",
    "        token += 1\n",
    "    \n",
    "V = len(dictionary)\n",
    "print('dictionary size (number of distinct words): ', V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('and', 0.4351672656897982)\n",
      "('queen', 0.21011888305225324)\n",
      "('cat', 0.007306765670050159)\n",
      "('turtle', 0.1305738773253288)\n"
     ]
    }
   ],
   "source": [
    "#past word as feature\n",
    "\n",
    "posterior_1word = np.zeros((V, V))\n",
    "for k in range(1,D):\n",
    "    word = corpus[k]\n",
    "    token = tokenize[word]\n",
    "    \n",
    "    past_word = corpus[k-1]\n",
    "    past_token = tokenize[past_word]\n",
    "    posterior_1word[past_token, token] += 1\n",
    "    \n",
    "\n",
    "prior = np.zeros(V)\n",
    "for k in range(D-1):\n",
    "    word = corpus[k]\n",
    "    token = tokenize[word]\n",
    "    \n",
    "    prior[token] += 1\n",
    "prior = prior / np.sum(prior)\n",
    "\n",
    "def get_likelihood_2gram(word):\n",
    "    \n",
    "    token = tokenize[word]\n",
    "    likelihood = posterior_1word[token,:]*prior\n",
    "    return(likelihood)\n",
    "def pred_2gram(word):\n",
    "    likelihood = get_likelihood_2gram(word)\n",
    "    i = np.argmax(likelihood)\n",
    "    return(dictionary[i], likelihood[i])\n",
    "print(pred_2gram('alice'))\n",
    "print(pred_2gram('the'))\n",
    "print(pred_2gram('cheshire'))\n",
    "print(pred_2gram('mock'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22366602156483273\n"
     ]
    }
   ],
   "source": [
    "#get accuracy of bigram classifier\n",
    "correct = 0.\n",
    "for k in range(1,D):\n",
    "    word = corpus[k]\n",
    "    prev_word = corpus[k-1]\n",
    "    pred_word = pred_2gram(prev_word)[0]\n",
    "    if word == pred_word: correct += 1\n",
    "print(correct / (D-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cards', 0.0010663928275208342)\n",
      "('you', 0.707018444646313)\n",
      "('up', 0.19716418499940755)\n"
     ]
    }
   ],
   "source": [
    "#past 2 words as features\n",
    "\n",
    "posterior_2words = np.zeros((V, V))\n",
    "for k in range(2,D):\n",
    "    word = corpus[k]\n",
    "    token = tokenize[word]\n",
    "    \n",
    "    past_word = corpus[k-2]\n",
    "    past_token = tokenize[past_word]\n",
    "    posterior_2words[past_token,token] += 1\n",
    "\n",
    "posterior_2gram = np.vstack([posterior_1word,posterior_2words])\n",
    "\n",
    "\n",
    "def get_likelihood_3gram(word2ago,word1ago):\n",
    "    \n",
    "    token1ago = tokenize[word1ago]\n",
    "    token2ago = tokenize[word2ago]\n",
    "    likelihood = posterior_2gram[token1ago,:] * posterior_2gram[token2ago + V,:]  * prior\n",
    "    return likelihood\n",
    "def pred_3gram(word2ago,word1ago):\n",
    "    likelihood = get_likelihood_3gram(word2ago,word1ago)\n",
    "    i = np.argmax(likelihood)\n",
    "    \n",
    "    return dictionary[i], likelihood[i]\n",
    "print(pred_3gram('pack','of'))\n",
    "print(pred_3gram('the','mad'))\n",
    "print(pred_3gram('she','jumped'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36087523203918004\n"
     ]
    }
   ],
   "source": [
    "#get accuracy of bigram classifier\n",
    "correct = 0.\n",
    "for k in range(2,D):\n",
    "    word = corpus[k]\n",
    "    prev_word = corpus[k-1]\n",
    "    prev2_word = corpus[k-2]\n",
    "    pred_word = pred_3gram(prev2_word,prev_word)[0]\n",
    "    if word == pred_word: correct += 1\n",
    "print(correct / (D-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice and the queen and the queen and the queen and the queen and the queen and the queen and the queen and the queen and\n",
      "alice was the little of the queen and the queen and the queen and the queen and the queen and the queen and the queen and the\n"
     ]
    }
   ],
   "source": [
    "word = 'alice'\n",
    "gen_2gram = [word]\n",
    "for i in range(25):\n",
    "    word = pred_2gram(word)[0]\n",
    "    gen_2gram.append(word)\n",
    "print(' '.join(gen_2gram))\n",
    "\n",
    "\n",
    "word_bigram = ['alice','was']\n",
    "gen_3gram = word_bigram\n",
    "for i in range(25):\n",
    "    word = pred_3gram(word_bigram[0],word_bigram[1])[0]\n",
    "    gen_3gram.append(word)\n",
    "    word_bigram = [word_bigram[1],word]\n",
    "print(' '.join(gen_3gram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice it said the mouse the mock turtle to the queen had a little alice was the poor alice as the gryphon the hatter the other\n",
      "alice was the white and that the gryphon and the other and i to be a very little of it was the little the mock turtle in\n"
     ]
    }
   ],
   "source": [
    "word = 'alice'\n",
    "gen_2gram = [word]\n",
    "for i in range(25):\n",
    "    likelihood = get_likelihood_2gram(word)\n",
    "    word = random.choices(dictionary,likelihood)[0]\n",
    "    gen_2gram.append(word)\n",
    "print(' '.join(gen_2gram))\n",
    "\n",
    "\n",
    "word_bigram = ['alice','was']\n",
    "gen_3gram = word_bigram\n",
    "for i in range(25):\n",
    "    likelihood = get_likelihood_3gram(word_bigram[0],word_bigram[1])\n",
    "    word = random.choices(dictionary,likelihood)[0]\n",
    "    gen_3gram.append(word)\n",
    "    word_bigram = [word_bigram[1],word]\n",
    "print(' '.join(gen_3gram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
